{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code has two aims: \n",
    "# 1. To clean Chinese text of the city-level information and\n",
    "# 2. To merge city-level scores of all kinds with our data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "# 1.1 Read the data and unify the name for four 直辖市 and some 省直管 districts\n",
    "\n",
    "city = pd.read_excel(\"cities.xlsx\").drop(\"Citycode\", axis=1).rename(columns={\"Cityname\": \"city\"})\n",
    "data = pd.read_csv(\"output.csv\")\n",
    "\n",
    "pc = {50:\"重庆\", 11:\"北京\", 12:\"天津\", 31:\"上海\"}\n",
    "\n",
    "for key, value in pc.items():\n",
    "    data.loc[data[\"Destination\"] == key, \"city\"] = value\n",
    "    \n",
    "data.loc[(data['city'] == \"省直辖\") & (data['Destination'] == 42), \"city\"] = \"湖北省直管\"\n",
    "\n",
    "    \n",
    "# 1.2 Unify city names in the data file with those in the city file, enabling double-ended check \n",
    "\n",
    "def modify_row(row, compare_data):     \n",
    "    for ind in compare_data['city']:\n",
    "        if (ind.find(row) != -1) | (row.find(ind) != -1):\n",
    "            row = ind\n",
    "            break\n",
    "    return row  \n",
    "\n",
    "data['city'] = data['city'].apply(lambda row: modify_row(row, city))\n",
    "\n",
    "\n",
    "\n",
    "# 1.3.1 First round check: Discover the city names in data file that have not been matched\n",
    "\n",
    "def merge_check(data, city):\n",
    "    ud = pd.DataFrame(data['city'].unique()).rename(columns={0: \"c1\"})\n",
    "    uc = pd.DataFrame(city['city'].unique()).rename(columns={0: \"c2\"})\n",
    "    data_city = pd.merge(ud, uc, how ='left', left_on = \"c1\", right_on = \"c2\")\n",
    "    return data_city[data_city['c2'].isnull() == True]\n",
    "\n",
    "check_1st = merge_check(data, city) \n",
    "len(check_1st)                        # Total 28 names have not been matched yet\n",
    "\n",
    "\n",
    "\n",
    "# Manually inspect them one by one and document these names in a dictionary\n",
    "\n",
    "'''for i in data['city'].unique():\n",
    "    if i.find(\"红河\") != -1: # \"黔南\"\n",
    "        print(i)'''\n",
    "\n",
    "\n",
    "d = {\"阿坝藏\":\"阿坝州\", \"博州\":\"博尔塔拉州\", \"博尔塔拉蒙古自治州\":\"博尔塔拉州\", \"海西州\":\"海西蒙古族藏族自治州\", \n",
    "     \"黔东南州\":\"黔东南苗族侗族自治州\", \"黔东南州苗族侗族自治\":\"黔东南苗族侗族自治州\", \"海南州\":\"海南藏族自治州\", \n",
    "     \"红河州哈尼\":\"红河哈尼族彝族自治州\", \"红河洲\":\"红河哈尼族彝族自治州\", \"红河州\":\"红河哈尼族彝族自治州\", \n",
    "     \"海东市\":\"海东地区\", \"昌吉回族自\":\"昌吉州\", \"昌吉回族自治州\":\"昌吉州\", \"湘西土家族\":\"湘西州\", \"湘西土家族苗族自治州\":\"湘西州\",\n",
    "     \"伊犁州\":\"伊犁哈萨克自治州\",  \"日喀则市\":\"日喀则地区\", \"黔南州\":\"黔南布依族苗族自治州\",  \"吐鲁番市\":\"吐鲁番地区\",\n",
    "     \"甘孜藏族自治州\":\"甘孜州\", \"巴音郭楞蒙古族自治州\":\"巴音郭楞蒙古自治州\", \"西双版纳傣族自治州\":\"西双版纳州\",\n",
    "     \"黔西南布依族苗族自治\":\"黔西南州\", \"海北藏族自治州\":\"海北州\", \"甘南藏族自治州\": \"甘南州\"}\n",
    "\n",
    "\n",
    "\n",
    "# 1.3.2 Second round check\n",
    "\n",
    "for old, new in d.items():\n",
    "    data.loc[data[\"city\"] == old, \"city\"] = new\n",
    "    \n",
    "check_2nd = merge_check(data, city)\n",
    "len(check_2nd)                        # All names have been matched now :)\n",
    "\n",
    "\n",
    "# 1.4 Randomly generage a series of pseudo city code\n",
    "\n",
    "random.seed(7735)\n",
    "code = random.sample(range(1,len(data['city'].unique())+1), len(data['city'].unique()))\n",
    "citycode = pd.DataFrame({\"city\":data['city'].unique(), \"citycode\":code})\n",
    "city = pd.merge(city, citycode, left_on = \"city\", right_on = \"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Merge city-level scores\n",
    "\n",
    "# 2.1 Classifying city size based on population and merge three files from above data, city & citycode\n",
    "\n",
    "city[\"city_size\"] = city[\"2013 Population (10000 persons)\"]\n",
    "\n",
    "def resize(value):\n",
    "    if value < 50:\n",
    "        value = 11\n",
    "    elif value < 100:\n",
    "        value = 12\n",
    "    elif value < 300:\n",
    "        value = 13\n",
    "    elif value < 500:\n",
    "        value = 14\n",
    "    else:\n",
    "        value = 15\n",
    "    return value\n",
    "        \n",
    "city[\"city_size\"] = city[\"city_size\"].apply(lambda row: resize(row))\n",
    "# city[\"city_size\"].value_counts() \n",
    "\n",
    "data_city = pd.merge(data, city, how='left', left_on = \"city\", right_on = \"city\")\n",
    "\n",
    "# 2.2 Reshape the file containing scores info for merging purpose\n",
    "\n",
    "scores = pd.read_excel(r\"c:\\Users\\User\\Desktop\\Clustering\\Scores_City.xlsx\", index_col = 0)\n",
    "s = scores.iloc[:, :24]\n",
    "m = scores.iloc[:, 24:48]\n",
    "b1 = scores.iloc[:, 48:72]\n",
    "b2 = scores.iloc[:, 72:96]\n",
    "mega = scores.iloc[:, 96:120]\n",
    "\n",
    "scores = pd.DataFrame() \n",
    "\n",
    "for (df, size) in zip([s, m, b1, b2, mega], [11, 12, 13, 14, 15]):\n",
    "    df[\"_size\"] = size                                                    # create the city size variable for each df\n",
    "    df.columns = [\"city_\" + col[col.find(\"_\")+1: ] for col in df.columns] # rename the column to be the same across city sizes\n",
    "    scores = scores.append(df)                                            # append all the dfs together\n",
    "\n",
    "# 2.3 \n",
    "scores = scores.reset_index()\n",
    "output = pd.merge(data_city, scores, how = \"left\", left_on = [\"Destination\", \"city_size\"], right_on = [\"Procode\", \"city_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"../3. SelectionAnalysis/output_city.csv\", encoding = \"utf8\") #output.to_excel(\"output_city.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
